{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "(5851, 28, 28, 1)\n",
      ">1, d1=0.696, d2=0.694 g=0.692, a1=37, a2=0\n",
      ">2, d1=0.658, d2=0.696 g=0.690, a1=100, a2=0\n",
      ">3, d1=0.626, d2=0.699 g=0.687, a1=100, a2=0\n",
      ">4, d1=0.594, d2=0.704 g=0.682, a1=100, a2=0\n",
      ">5, d1=0.559, d2=0.713 g=0.674, a1=100, a2=0\n",
      ">6, d1=0.522, d2=0.727 g=0.661, a1=100, a2=0\n",
      ">7, d1=0.485, d2=0.749 g=0.643, a1=100, a2=0\n",
      ">8, d1=0.458, d2=0.781 g=0.620, a1=100, a2=0\n",
      ">9, d1=0.427, d2=0.820 g=0.596, a1=100, a2=0\n",
      ">10, d1=0.406, d2=0.851 g=0.582, a1=100, a2=0\n",
      ">11, d1=0.395, d2=0.859 g=0.584, a1=100, a2=0\n",
      ">12, d1=0.391, d2=0.844 g=0.603, a1=100, a2=0\n",
      ">13, d1=0.401, d2=0.804 g=0.640, a1=100, a2=0\n",
      ">14, d1=0.410, d2=0.755 g=0.687, a1=100, a2=0\n",
      ">15, d1=0.390, d2=0.698 g=0.754, a1=100, a2=17\n",
      ">16, d1=0.411, d2=0.634 g=0.823, a1=100, a2=100\n",
      ">17, d1=0.401, d2=0.576 g=0.903, a1=100, a2=100\n",
      ">18, d1=0.401, d2=0.519 g=0.991, a1=100, a2=100\n",
      ">19, d1=0.413, d2=0.464 g=1.085, a1=100, a2=100\n",
      ">20, d1=0.394, d2=0.413 g=1.186, a1=100, a2=100\n",
      ">21, d1=0.369, d2=0.365 g=1.296, a1=98, a2=100\n",
      ">22, d1=0.358, d2=0.322 g=1.414, a1=100, a2=100\n",
      ">23, d1=0.345, d2=0.282 g=1.531, a1=96, a2=100\n",
      ">24, d1=0.334, d2=0.249 g=1.638, a1=98, a2=100\n",
      ">25, d1=0.274, d2=0.218 g=1.762, a1=98, a2=100\n",
      ">26, d1=0.296, d2=0.195 g=1.857, a1=100, a2=100\n",
      ">27, d1=0.272, d2=0.178 g=1.948, a1=95, a2=100\n",
      ">28, d1=0.277, d2=0.163 g=2.015, a1=96, a2=100\n",
      ">29, d1=0.211, d2=0.150 g=2.117, a1=96, a2=100\n",
      ">30, d1=0.200, d2=0.133 g=2.213, a1=98, a2=100\n",
      ">31, d1=0.183, d2=0.120 g=2.307, a1=98, a2=100\n",
      ">32, d1=0.194, d2=0.111 g=2.377, a1=96, a2=100\n",
      ">33, d1=0.149, d2=0.102 g=2.469, a1=100, a2=100\n",
      ">34, d1=0.186, d2=0.095 g=2.508, a1=96, a2=100\n",
      ">35, d1=0.144, d2=0.091 g=2.571, a1=100, a2=100\n",
      ">36, d1=0.145, d2=0.085 g=2.635, a1=96, a2=100\n",
      ">37, d1=0.108, d2=0.078 g=2.727, a1=98, a2=100\n",
      ">38, d1=0.097, d2=0.069 g=2.822, a1=100, a2=100\n",
      ">39, d1=0.110, d2=0.066 g=2.883, a1=100, a2=100\n",
      ">40, d1=0.136, d2=0.065 g=2.890, a1=100, a2=100\n",
      ">41, d1=0.073, d2=0.060 g=2.982, a1=100, a2=100\n",
      ">42, d1=0.064, d2=0.053 g=3.089, a1=100, a2=100\n",
      ">43, d1=0.077, d2=0.049 g=3.157, a1=95, a2=100\n",
      ">44, d1=0.070, d2=0.046 g=3.215, a1=100, a2=100\n",
      ">45, d1=0.082, d2=0.045 g=3.210, a1=100, a2=100\n",
      ">46, d1=0.079, d2=0.046 g=3.184, a1=98, a2=100\n",
      ">47, d1=0.063, d2=0.068 g=3.216, a1=100, a2=98\n",
      ">48, d1=0.064, d2=0.082 g=3.039, a1=100, a2=100\n",
      ">49, d1=0.072, d2=0.128 g=2.540, a1=96, a2=96\n",
      ">50, d1=0.059, d2=0.266 g=1.640, a1=100, a2=93\n",
      ">51, d1=0.073, d2=0.883 g=0.617, a1=95, a2=7\n",
      ">52, d1=0.105, d2=1.661 g=0.289, a1=96, a2=0\n",
      ">53, d1=0.068, d2=1.982 g=0.265, a1=98, a2=0\n",
      ">54, d1=0.065, d2=1.793 g=0.318, a1=100, a2=0\n",
      ">55, d1=0.052, d2=1.379 g=0.462, a1=100, a2=0\n",
      ">56, d1=0.047, d2=1.087 g=0.599, a1=100, a2=3\n",
      ">57, d1=0.028, d2=0.767 g=0.823, a1=100, a2=46\n",
      ">58, d1=0.029, d2=0.599 g=0.996, a1=100, a2=76\n",
      ">59, d1=0.029, d2=0.486 g=1.069, a1=100, a2=100\n",
      ">60, d1=0.025, d2=0.466 g=1.056, a1=100, a2=100\n",
      ">61, d1=0.021, d2=0.485 g=1.000, a1=100, a2=100\n",
      ">62, d1=0.019, d2=0.518 g=0.931, a1=100, a2=100\n",
      ">63, d1=0.019, d2=0.546 g=0.883, a1=100, a2=100\n",
      ">64, d1=0.015, d2=0.568 g=0.851, a1=100, a2=100\n",
      ">65, d1=0.015, d2=0.582 g=0.829, a1=100, a2=100\n",
      ">66, d1=0.019, d2=0.596 g=0.812, a1=100, a2=100\n",
      ">67, d1=0.012, d2=0.611 g=0.795, a1=100, a2=100\n",
      ">68, d1=0.011, d2=0.628 g=0.775, a1=100, a2=100\n",
      ">69, d1=0.013, d2=0.647 g=0.757, a1=100, a2=100\n",
      ">70, d1=0.013, d2=0.657 g=0.742, a1=100, a2=90\n",
      ">71, d1=0.014, d2=0.656 g=0.748, a1=100, a2=81\n",
      ">72, d1=0.017, d2=0.650 g=0.760, a1=100, a2=79\n",
      ">73, d1=0.021, d2=0.655 g=0.767, a1=100, a2=68\n",
      ">74, d1=0.022, d2=0.637 g=0.792, a1=100, a2=78\n",
      ">75, d1=0.032, d2=0.619 g=0.822, a1=100, a2=84\n",
      ">76, d1=0.039, d2=0.601 g=0.826, a1=100, a2=90\n",
      ">77, d1=0.055, d2=0.611 g=0.832, a1=100, a2=93\n",
      ">78, d1=0.045, d2=0.597 g=0.840, a1=100, a2=93\n",
      ">79, d1=0.068, d2=0.606 g=0.823, a1=100, a2=98\n",
      ">80, d1=0.075, d2=0.630 g=0.791, a1=100, a2=93\n",
      ">81, d1=0.066, d2=0.639 g=0.776, a1=100, a2=85\n",
      ">82, d1=0.093, d2=0.669 g=0.764, a1=100, a2=70\n",
      ">83, d1=0.065, d2=0.675 g=0.751, a1=100, a2=64\n",
      ">84, d1=0.072, d2=0.676 g=0.760, a1=100, a2=60\n",
      ">85, d1=0.077, d2=0.681 g=0.784, a1=100, a2=54\n",
      ">86, d1=0.152, d2=0.679 g=0.767, a1=98, a2=62\n",
      ">87, d1=0.131, d2=0.700 g=0.762, a1=100, a2=43\n",
      ">88, d1=0.114, d2=0.691 g=0.816, a1=100, a2=54\n",
      ">89, d1=0.158, d2=0.712 g=0.820, a1=98, a2=40\n",
      ">90, d1=0.185, d2=0.710 g=0.824, a1=98, a2=43\n",
      ">91, d1=0.234, d2=0.763 g=0.784, a1=95, a2=26\n",
      ">92, d1=0.206, d2=0.754 g=0.796, a1=100, a2=26\n",
      ">93, d1=0.251, d2=0.784 g=0.828, a1=98, a2=18\n",
      ">94, d1=0.295, d2=0.734 g=0.819, a1=98, a2=40\n",
      ">95, d1=0.313, d2=0.732 g=0.793, a1=96, a2=40\n",
      ">96, d1=0.365, d2=0.862 g=0.801, a1=95, a2=7\n",
      ">97, d1=0.335, d2=0.817 g=0.899, a1=95, a2=14\n",
      ">98, d1=0.444, d2=0.743 g=0.898, a1=93, a2=32\n",
      ">99, d1=0.477, d2=0.785 g=0.881, a1=85, a2=23\n",
      ">100, d1=0.510, d2=0.782 g=0.859, a1=82, a2=20\n",
      ">101, d1=0.468, d2=0.770 g=0.888, a1=90, a2=31\n",
      ">102, d1=0.515, d2=0.790 g=0.917, a1=79, a2=18\n",
      ">103, d1=0.581, d2=0.771 g=0.900, a1=82, a2=26\n",
      ">104, d1=0.594, d2=0.790 g=0.926, a1=73, a2=20\n",
      ">105, d1=0.666, d2=0.772 g=0.906, a1=65, a2=21\n",
      ">106, d1=0.635, d2=0.739 g=0.896, a1=70, a2=32\n",
      ">107, d1=0.642, d2=0.748 g=0.909, a1=64, a2=29\n",
      ">108, d1=0.658, d2=0.715 g=0.916, a1=62, a2=37\n",
      ">109, d1=0.645, d2=0.702 g=0.929, a1=64, a2=43\n",
      ">110, d1=0.679, d2=0.701 g=0.894, a1=54, a2=46\n",
      ">111, d1=0.636, d2=0.701 g=0.905, a1=67, a2=48\n",
      ">112, d1=0.656, d2=0.697 g=0.903, a1=64, a2=48\n",
      ">113, d1=0.664, d2=0.680 g=0.904, a1=62, a2=64\n",
      ">114, d1=0.655, d2=0.700 g=0.910, a1=67, a2=54\n",
      ">115, d1=0.667, d2=0.682 g=0.916, a1=54, a2=56\n",
      ">116, d1=0.651, d2=0.675 g=0.900, a1=70, a2=59\n",
      ">117, d1=0.656, d2=0.651 g=0.896, a1=59, a2=78\n",
      ">118, d1=0.638, d2=0.691 g=0.897, a1=70, a2=62\n",
      ">119, d1=0.624, d2=0.691 g=0.904, a1=73, a2=56\n",
      ">120, d1=0.686, d2=0.667 g=0.903, a1=56, a2=60\n",
      ">121, d1=0.652, d2=0.695 g=0.865, a1=62, a2=45\n",
      ">122, d1=0.643, d2=0.708 g=0.845, a1=65, a2=50\n",
      ">123, d1=0.657, d2=0.742 g=0.904, a1=60, a2=37\n",
      ">124, d1=0.695, d2=0.698 g=0.871, a1=54, a2=56\n",
      ">125, d1=0.685, d2=0.708 g=0.860, a1=59, a2=37\n",
      ">126, d1=0.676, d2=0.697 g=0.828, a1=64, a2=54\n",
      ">127, d1=0.682, d2=0.689 g=0.830, a1=56, a2=50\n",
      ">128, d1=0.722, d2=0.723 g=0.825, a1=45, a2=40\n",
      ">129, d1=0.687, d2=0.737 g=0.819, a1=54, a2=37\n",
      ">130, d1=0.676, d2=0.711 g=0.811, a1=59, a2=42\n",
      ">131, d1=0.665, d2=0.727 g=0.826, a1=62, a2=39\n",
      ">132, d1=0.649, d2=0.738 g=0.803, a1=59, a2=35\n",
      ">133, d1=0.672, d2=0.688 g=0.827, a1=59, a2=50\n",
      ">134, d1=0.697, d2=0.727 g=0.809, a1=50, a2=31\n",
      ">135, d1=0.692, d2=0.736 g=0.798, a1=54, a2=26\n",
      ">136, d1=0.728, d2=0.728 g=0.785, a1=42, a2=28\n",
      ">137, d1=0.750, d2=0.726 g=0.768, a1=40, a2=32\n",
      ">138, d1=0.661, d2=0.736 g=0.776, a1=60, a2=32\n",
      ">139, d1=0.681, d2=0.754 g=0.782, a1=59, a2=29\n",
      ">140, d1=0.630, d2=0.740 g=0.803, a1=64, a2=31\n",
      ">141, d1=0.681, d2=0.730 g=0.802, a1=56, a2=39\n",
      ">142, d1=0.671, d2=0.711 g=0.799, a1=57, a2=34\n",
      ">143, d1=0.684, d2=0.703 g=0.806, a1=54, a2=51\n",
      ">144, d1=0.695, d2=0.711 g=0.804, a1=59, a2=42\n",
      ">145, d1=0.704, d2=0.693 g=0.801, a1=50, a2=54\n",
      ">146, d1=0.699, d2=0.729 g=0.782, a1=54, a2=34\n",
      ">147, d1=0.678, d2=0.705 g=0.793, a1=56, a2=54\n",
      ">148, d1=0.656, d2=0.718 g=0.794, a1=59, a2=37\n",
      ">149, d1=0.674, d2=0.692 g=0.809, a1=54, a2=46\n",
      ">150, d1=0.672, d2=0.703 g=0.801, a1=62, a2=42\n",
      ">151, d1=0.649, d2=0.699 g=0.822, a1=65, a2=46\n",
      ">152, d1=0.667, d2=0.694 g=0.817, a1=60, a2=50\n",
      ">153, d1=0.674, d2=0.690 g=0.819, a1=62, a2=53\n",
      ">154, d1=0.690, d2=0.662 g=0.813, a1=62, a2=67\n",
      ">155, d1=0.636, d2=0.676 g=0.835, a1=70, a2=65\n",
      ">156, d1=0.684, d2=0.656 g=0.809, a1=59, a2=78\n",
      ">157, d1=0.691, d2=0.678 g=0.803, a1=56, a2=60\n",
      ">158, d1=0.668, d2=0.681 g=0.809, a1=62, a2=59\n",
      ">159, d1=0.690, d2=0.672 g=0.815, a1=62, a2=64\n",
      ">160, d1=0.659, d2=0.691 g=0.834, a1=65, a2=48\n",
      ">161, d1=0.671, d2=0.704 g=0.814, a1=53, a2=42\n",
      ">162, d1=0.707, d2=0.684 g=0.832, a1=46, a2=56\n",
      ">163, d1=0.666, d2=0.666 g=0.850, a1=62, a2=56\n",
      ">164, d1=0.676, d2=0.679 g=0.843, a1=51, a2=50\n",
      ">165, d1=0.674, d2=0.664 g=0.847, a1=57, a2=65\n",
      ">166, d1=0.673, d2=0.655 g=0.842, a1=64, a2=70\n",
      ">167, d1=0.644, d2=0.652 g=0.854, a1=70, a2=65\n",
      ">168, d1=0.647, d2=0.648 g=0.854, a1=64, a2=71\n",
      ">169, d1=0.664, d2=0.660 g=0.847, a1=68, a2=67\n",
      ">170, d1=0.701, d2=0.656 g=0.841, a1=51, a2=71\n",
      ">171, d1=0.654, d2=0.656 g=0.854, a1=65, a2=71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">172, d1=0.695, d2=0.646 g=0.858, a1=56, a2=76\n",
      ">173, d1=0.704, d2=0.635 g=0.839, a1=54, a2=75\n",
      ">174, d1=0.667, d2=0.662 g=0.846, a1=60, a2=62\n",
      ">175, d1=0.661, d2=0.667 g=0.848, a1=62, a2=64\n",
      ">176, d1=0.648, d2=0.671 g=0.841, a1=68, a2=67\n",
      ">177, d1=0.687, d2=0.642 g=0.842, a1=57, a2=79\n",
      ">178, d1=0.684, d2=0.640 g=0.834, a1=59, a2=75\n",
      ">179, d1=0.682, d2=0.670 g=0.835, a1=57, a2=56\n",
      ">180, d1=0.679, d2=0.663 g=0.836, a1=53, a2=62\n",
      ">181, d1=0.694, d2=0.670 g=0.827, a1=46, a2=67\n",
      ">182, d1=0.683, d2=0.672 g=0.825, a1=56, a2=60\n",
      ">183, d1=0.683, d2=0.679 g=0.816, a1=57, a2=64\n",
      ">184, d1=0.685, d2=0.669 g=0.797, a1=67, a2=67\n",
      ">185, d1=0.663, d2=0.666 g=0.819, a1=59, a2=67\n",
      ">186, d1=0.698, d2=0.688 g=0.803, a1=51, a2=54\n",
      ">187, d1=0.723, d2=0.684 g=0.815, a1=51, a2=59\n",
      ">188, d1=0.702, d2=0.690 g=0.806, a1=56, a2=50\n",
      ">189, d1=0.693, d2=0.668 g=0.798, a1=54, a2=67\n",
      ">190, d1=0.685, d2=0.680 g=0.780, a1=64, a2=59\n",
      ">191, d1=0.693, d2=0.700 g=0.804, a1=57, a2=54\n",
      ">192, d1=0.692, d2=0.684 g=0.788, a1=56, a2=59\n",
      ">193, d1=0.734, d2=0.708 g=0.785, a1=39, a2=57\n",
      ">194, d1=0.692, d2=0.682 g=0.798, a1=60, a2=56\n",
      ">195, d1=0.706, d2=0.700 g=0.798, a1=46, a2=54\n",
      ">196, d1=0.728, d2=0.695 g=0.813, a1=45, a2=50\n",
      ">197, d1=0.725, d2=0.706 g=0.770, a1=50, a2=57\n",
      ">198, d1=0.686, d2=0.681 g=0.774, a1=60, a2=56\n",
      ">199, d1=0.717, d2=0.709 g=0.767, a1=46, a2=50\n",
      ">200, d1=0.713, d2=0.678 g=0.781, a1=46, a2=56\n",
      ">201, d1=0.725, d2=0.741 g=0.778, a1=39, a2=45\n",
      ">202, d1=0.729, d2=0.684 g=0.777, a1=46, a2=54\n",
      ">203, d1=0.703, d2=0.721 g=0.792, a1=51, a2=46\n",
      ">204, d1=0.692, d2=0.700 g=0.800, a1=54, a2=56\n",
      ">205, d1=0.735, d2=0.760 g=0.788, a1=54, a2=39\n",
      ">206, d1=0.760, d2=0.696 g=0.768, a1=42, a2=53\n",
      ">207, d1=0.734, d2=0.705 g=0.770, a1=40, a2=54\n",
      ">208, d1=0.722, d2=0.761 g=0.746, a1=48, a2=40\n",
      ">209, d1=0.745, d2=0.710 g=0.795, a1=32, a2=56\n",
      ">210, d1=0.710, d2=0.741 g=0.804, a1=56, a2=40\n",
      ">211, d1=0.707, d2=0.726 g=0.760, a1=54, a2=48\n",
      ">212, d1=0.747, d2=0.695 g=0.778, a1=35, a2=53\n",
      ">213, d1=0.746, d2=0.724 g=0.771, a1=46, a2=43\n",
      ">214, d1=0.756, d2=0.711 g=0.754, a1=39, a2=50\n",
      ">215, d1=0.730, d2=0.713 g=0.744, a1=39, a2=51\n",
      ">216, d1=0.710, d2=0.747 g=0.782, a1=51, a2=43\n",
      ">217, d1=0.737, d2=0.755 g=0.775, a1=42, a2=40\n",
      ">218, d1=0.755, d2=0.768 g=0.761, a1=34, a2=35\n",
      ">219, d1=0.718, d2=0.726 g=0.781, a1=42, a2=48\n",
      ">220, d1=0.763, d2=0.748 g=0.780, a1=31, a2=35\n",
      ">221, d1=0.764, d2=0.740 g=0.777, a1=31, a2=48\n",
      ">222, d1=0.761, d2=0.744 g=0.780, a1=39, a2=42\n",
      ">223, d1=0.750, d2=0.761 g=0.760, a1=45, a2=39\n",
      ">224, d1=0.739, d2=0.718 g=0.760, a1=45, a2=48\n",
      ">225, d1=0.765, d2=0.712 g=0.751, a1=29, a2=43\n",
      ">226, d1=0.760, d2=0.748 g=0.744, a1=31, a2=39\n",
      ">227, d1=0.751, d2=0.748 g=0.721, a1=32, a2=42\n",
      ">228, d1=0.739, d2=0.750 g=0.740, a1=35, a2=32\n",
      ">229, d1=0.739, d2=0.762 g=0.727, a1=32, a2=26\n",
      ">230, d1=0.745, d2=0.740 g=0.727, a1=32, a2=32\n",
      ">231, d1=0.743, d2=0.761 g=0.746, a1=45, a2=26\n",
      ">232, d1=0.756, d2=0.736 g=0.744, a1=31, a2=31\n",
      ">233, d1=0.749, d2=0.728 g=0.733, a1=37, a2=32\n",
      ">234, d1=0.722, d2=0.740 g=0.736, a1=50, a2=26\n",
      ">235, d1=0.762, d2=0.731 g=0.727, a1=31, a2=39\n",
      ">236, d1=0.731, d2=0.726 g=0.737, a1=48, a2=40\n",
      ">237, d1=0.749, d2=0.757 g=0.737, a1=34, a2=31\n",
      ">238, d1=0.730, d2=0.730 g=0.733, a1=42, a2=34\n",
      ">239, d1=0.738, d2=0.722 g=0.733, a1=35, a2=34\n",
      ">240, d1=0.744, d2=0.720 g=0.726, a1=35, a2=39\n",
      ">241, d1=0.729, d2=0.721 g=0.720, a1=39, a2=37\n",
      ">242, d1=0.731, d2=0.729 g=0.729, a1=46, a2=39\n",
      ">243, d1=0.709, d2=0.726 g=0.743, a1=54, a2=31\n",
      ">244, d1=0.731, d2=0.731 g=0.746, a1=37, a2=31\n",
      ">245, d1=0.748, d2=0.720 g=0.741, a1=32, a2=42\n",
      ">246, d1=0.705, d2=0.725 g=0.754, a1=46, a2=37\n",
      ">247, d1=0.712, d2=0.698 g=0.746, a1=46, a2=54\n",
      ">248, d1=0.705, d2=0.712 g=0.754, a1=53, a2=40\n",
      ">249, d1=0.705, d2=0.689 g=0.753, a1=53, a2=46\n",
      ">250, d1=0.730, d2=0.693 g=0.737, a1=40, a2=54\n",
      ">251, d1=0.690, d2=0.732 g=0.750, a1=57, a2=32\n",
      ">252, d1=0.696, d2=0.715 g=0.745, a1=45, a2=35\n",
      ">253, d1=0.723, d2=0.712 g=0.748, a1=42, a2=43\n",
      ">254, d1=0.713, d2=0.727 g=0.730, a1=43, a2=32\n",
      ">255, d1=0.724, d2=0.722 g=0.735, a1=40, a2=34\n",
      ">256, d1=0.699, d2=0.753 g=0.745, a1=46, a2=29\n",
      ">257, d1=0.690, d2=0.724 g=0.743, a1=54, a2=39\n",
      ">258, d1=0.714, d2=0.719 g=0.747, a1=45, a2=37\n",
      ">259, d1=0.713, d2=0.710 g=0.754, a1=40, a2=37\n",
      ">260, d1=0.725, d2=0.719 g=0.728, a1=39, a2=39\n",
      ">261, d1=0.708, d2=0.734 g=0.740, a1=51, a2=28\n",
      ">262, d1=0.698, d2=0.712 g=0.736, a1=54, a2=42\n",
      ">263, d1=0.710, d2=0.708 g=0.738, a1=50, a2=43\n",
      ">264, d1=0.712, d2=0.729 g=0.732, a1=46, a2=31\n",
      ">265, d1=0.710, d2=0.724 g=0.736, a1=42, a2=26\n",
      ">266, d1=0.713, d2=0.713 g=0.749, a1=35, a2=39\n",
      ">267, d1=0.737, d2=0.698 g=0.735, a1=34, a2=48\n",
      ">268, d1=0.712, d2=0.701 g=0.735, a1=42, a2=43\n",
      ">269, d1=0.705, d2=0.713 g=0.750, a1=48, a2=40\n",
      ">270, d1=0.711, d2=0.719 g=0.749, a1=39, a2=29\n",
      ">271, d1=0.729, d2=0.708 g=0.758, a1=29, a2=50\n",
      ">272, d1=0.708, d2=0.673 g=0.747, a1=43, a2=59\n",
      ">273, d1=0.714, d2=0.718 g=0.748, a1=45, a2=34\n",
      ">274, d1=0.712, d2=0.689 g=0.747, a1=46, a2=48\n",
      ">275, d1=0.718, d2=0.705 g=0.764, a1=45, a2=43\n",
      ">276, d1=0.716, d2=0.698 g=0.749, a1=42, a2=46\n",
      ">277, d1=0.711, d2=0.713 g=0.751, a1=50, a2=35\n",
      ">278, d1=0.670, d2=0.692 g=0.743, a1=62, a2=46\n",
      ">279, d1=0.706, d2=0.699 g=0.743, a1=46, a2=40\n",
      ">280, d1=0.713, d2=0.691 g=0.759, a1=42, a2=50\n",
      ">281, d1=0.703, d2=0.696 g=0.744, a1=45, a2=50\n",
      ">282, d1=0.692, d2=0.693 g=0.761, a1=54, a2=43\n",
      ">283, d1=0.696, d2=0.701 g=0.744, a1=46, a2=56\n",
      ">284, d1=0.706, d2=0.693 g=0.746, a1=46, a2=54\n",
      ">285, d1=0.697, d2=0.697 g=0.763, a1=56, a2=50\n",
      ">286, d1=0.703, d2=0.706 g=0.748, a1=43, a2=43\n",
      ">287, d1=0.710, d2=0.714 g=0.743, a1=43, a2=43\n",
      ">288, d1=0.713, d2=0.693 g=0.753, a1=45, a2=45\n",
      ">289, d1=0.713, d2=0.715 g=0.748, a1=42, a2=40\n",
      ">290, d1=0.702, d2=0.721 g=0.750, a1=45, a2=34\n",
      ">291, d1=0.720, d2=0.709 g=0.745, a1=40, a2=40\n",
      ">292, d1=0.710, d2=0.715 g=0.746, a1=48, a2=45\n",
      ">293, d1=0.707, d2=0.710 g=0.724, a1=45, a2=43\n",
      ">294, d1=0.731, d2=0.711 g=0.732, a1=39, a2=43\n",
      ">295, d1=0.704, d2=0.733 g=0.734, a1=46, a2=31\n",
      ">296, d1=0.733, d2=0.724 g=0.737, a1=37, a2=35\n",
      ">297, d1=0.734, d2=0.710 g=0.735, a1=37, a2=42\n",
      ">298, d1=0.734, d2=0.709 g=0.728, a1=39, a2=45\n",
      ">299, d1=0.736, d2=0.731 g=0.729, a1=32, a2=34\n",
      ">300, d1=0.725, d2=0.722 g=0.734, a1=31, a2=29\n",
      ">301, d1=0.726, d2=0.732 g=0.722, a1=39, a2=39\n",
      ">302, d1=0.739, d2=0.713 g=0.726, a1=31, a2=32\n",
      ">303, d1=0.737, d2=0.733 g=0.712, a1=31, a2=28\n",
      ">304, d1=0.735, d2=0.725 g=0.723, a1=32, a2=35\n",
      ">305, d1=0.737, d2=0.730 g=0.707, a1=29, a2=35\n",
      ">306, d1=0.759, d2=0.734 g=0.719, a1=21, a2=31\n",
      ">307, d1=0.743, d2=0.744 g=0.717, a1=31, a2=28\n",
      ">308, d1=0.735, d2=0.737 g=0.707, a1=31, a2=21\n",
      ">309, d1=0.760, d2=0.745 g=0.704, a1=18, a2=21\n",
      ">310, d1=0.756, d2=0.753 g=0.700, a1=23, a2=20\n",
      ">311, d1=0.766, d2=0.725 g=0.701, a1=12, a2=28\n",
      ">312, d1=0.750, d2=0.749 g=0.694, a1=18, a2=21\n",
      ">313, d1=0.757, d2=0.740 g=0.707, a1=21, a2=21\n",
      ">314, d1=0.751, d2=0.741 g=0.705, a1=15, a2=26\n",
      ">315, d1=0.773, d2=0.741 g=0.689, a1=10, a2=18\n",
      ">316, d1=0.776, d2=0.741 g=0.708, a1=17, a2=18\n",
      ">317, d1=0.777, d2=0.731 g=0.694, a1=12, a2=28\n",
      ">318, d1=0.768, d2=0.754 g=0.703, a1=15, a2=18\n",
      ">319, d1=0.770, d2=0.733 g=0.703, a1=14, a2=28\n",
      ">320, d1=0.766, d2=0.750 g=0.700, a1=15, a2=15\n",
      ">321, d1=0.743, d2=0.743 g=0.701, a1=18, a2=12\n",
      ">322, d1=0.776, d2=0.732 g=0.697, a1=6, a2=18\n",
      ">323, d1=0.771, d2=0.743 g=0.697, a1=14, a2=15\n",
      ">324, d1=0.769, d2=0.727 g=0.703, a1=14, a2=25\n",
      ">325, d1=0.763, d2=0.741 g=0.701, a1=7, a2=25\n",
      ">326, d1=0.773, d2=0.745 g=0.703, a1=7, a2=9\n",
      ">327, d1=0.774, d2=0.734 g=0.695, a1=9, a2=18\n",
      ">328, d1=0.767, d2=0.737 g=0.696, a1=12, a2=15\n",
      ">329, d1=0.770, d2=0.729 g=0.709, a1=12, a2=23\n",
      ">330, d1=0.765, d2=0.738 g=0.705, a1=14, a2=23\n",
      ">331, d1=0.758, d2=0.729 g=0.703, a1=23, a2=23\n",
      ">332, d1=0.770, d2=0.735 g=0.714, a1=7, a2=18\n",
      ">333, d1=0.752, d2=0.727 g=0.708, a1=21, a2=29\n",
      ">334, d1=0.757, d2=0.733 g=0.709, a1=25, a2=20\n",
      ">335, d1=0.751, d2=0.723 g=0.717, a1=17, a2=23\n",
      ">336, d1=0.761, d2=0.722 g=0.726, a1=23, a2=29\n",
      ">337, d1=0.779, d2=0.707 g=0.709, a1=14, a2=39\n",
      ">338, d1=0.753, d2=0.724 g=0.717, a1=17, a2=29\n",
      ">339, d1=0.750, d2=0.715 g=0.715, a1=20, a2=37\n",
      ">340, d1=0.748, d2=0.717 g=0.713, a1=18, a2=31\n",
      ">341, d1=0.748, d2=0.709 g=0.720, a1=14, a2=40\n",
      ">342, d1=0.747, d2=0.712 g=0.717, a1=15, a2=39\n",
      ">343, d1=0.741, d2=0.718 g=0.726, a1=23, a2=29\n",
      ">344, d1=0.749, d2=0.716 g=0.725, a1=17, a2=34\n",
      ">345, d1=0.748, d2=0.704 g=0.717, a1=15, a2=37\n",
      ">346, d1=0.738, d2=0.715 g=0.715, a1=31, a2=39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">347, d1=0.742, d2=0.715 g=0.723, a1=31, a2=34\n",
      ">348, d1=0.730, d2=0.699 g=0.724, a1=20, a2=39\n",
      ">349, d1=0.740, d2=0.708 g=0.724, a1=28, a2=42\n",
      ">350, d1=0.752, d2=0.706 g=0.726, a1=26, a2=45\n",
      ">351, d1=0.754, d2=0.695 g=0.726, a1=25, a2=53\n",
      ">352, d1=0.735, d2=0.706 g=0.725, a1=29, a2=34\n",
      ">353, d1=0.738, d2=0.709 g=0.733, a1=26, a2=39\n",
      ">354, d1=0.741, d2=0.710 g=0.728, a1=20, a2=35\n",
      ">355, d1=0.735, d2=0.693 g=0.731, a1=28, a2=48\n",
      ">356, d1=0.727, d2=0.705 g=0.734, a1=32, a2=40\n",
      ">357, d1=0.722, d2=0.699 g=0.733, a1=37, a2=50\n",
      ">358, d1=0.737, d2=0.705 g=0.727, a1=29, a2=37\n",
      ">359, d1=0.743, d2=0.693 g=0.718, a1=21, a2=56\n",
      ">360, d1=0.741, d2=0.703 g=0.725, a1=25, a2=48\n",
      ">361, d1=0.725, d2=0.699 g=0.728, a1=31, a2=39\n",
      ">362, d1=0.733, d2=0.694 g=0.727, a1=28, a2=50\n",
      ">363, d1=0.724, d2=0.702 g=0.724, a1=35, a2=35\n",
      ">364, d1=0.740, d2=0.695 g=0.728, a1=25, a2=37\n",
      ">365, d1=0.726, d2=0.708 g=0.724, a1=34, a2=32\n",
      ">366, d1=0.728, d2=0.709 g=0.728, a1=29, a2=35\n",
      ">367, d1=0.729, d2=0.700 g=0.727, a1=29, a2=51\n",
      ">368, d1=0.713, d2=0.694 g=0.729, a1=43, a2=54\n",
      ">369, d1=0.744, d2=0.700 g=0.728, a1=25, a2=48\n",
      ">370, d1=0.722, d2=0.696 g=0.720, a1=29, a2=46\n",
      ">371, d1=0.719, d2=0.708 g=0.716, a1=37, a2=37\n",
      ">372, d1=0.717, d2=0.701 g=0.723, a1=35, a2=42\n",
      ">373, d1=0.725, d2=0.703 g=0.726, a1=39, a2=39\n",
      ">374, d1=0.706, d2=0.701 g=0.722, a1=48, a2=43\n",
      ">375, d1=0.720, d2=0.698 g=0.730, a1=35, a2=50\n",
      ">376, d1=0.724, d2=0.694 g=0.719, a1=35, a2=51\n",
      ">377, d1=0.703, d2=0.707 g=0.714, a1=45, a2=42\n",
      ">378, d1=0.731, d2=0.713 g=0.715, a1=32, a2=40\n",
      ">379, d1=0.712, d2=0.705 g=0.718, a1=43, a2=43\n",
      ">380, d1=0.719, d2=0.707 g=0.720, a1=42, a2=43\n",
      ">381, d1=0.721, d2=0.704 g=0.713, a1=34, a2=42\n",
      ">382, d1=0.724, d2=0.702 g=0.717, a1=32, a2=46\n",
      ">383, d1=0.708, d2=0.698 g=0.719, a1=39, a2=51\n",
      ">384, d1=0.705, d2=0.709 g=0.715, a1=51, a2=37\n",
      ">385, d1=0.714, d2=0.717 g=0.726, a1=43, a2=32\n",
      ">386, d1=0.716, d2=0.695 g=0.722, a1=40, a2=57\n",
      ">387, d1=0.725, d2=0.721 g=0.720, a1=34, a2=32\n",
      ">388, d1=0.707, d2=0.709 g=0.722, a1=46, a2=43\n",
      ">389, d1=0.725, d2=0.702 g=0.718, a1=29, a2=42\n",
      ">390, d1=0.717, d2=0.707 g=0.729, a1=34, a2=46\n",
      ">391, d1=0.719, d2=0.697 g=0.726, a1=35, a2=48\n",
      ">392, d1=0.712, d2=0.705 g=0.722, a1=43, a2=43\n",
      ">393, d1=0.724, d2=0.702 g=0.724, a1=34, a2=48\n",
      ">394, d1=0.732, d2=0.696 g=0.728, a1=25, a2=54\n",
      ">395, d1=0.716, d2=0.708 g=0.715, a1=40, a2=34\n",
      ">396, d1=0.712, d2=0.695 g=0.721, a1=43, a2=54\n",
      ">397, d1=0.708, d2=0.703 g=0.726, a1=39, a2=42\n",
      ">398, d1=0.720, d2=0.716 g=0.717, a1=34, a2=40\n",
      ">399, d1=0.714, d2=0.690 g=0.717, a1=34, a2=48\n",
      ">400, d1=0.710, d2=0.684 g=0.714, a1=32, a2=62\n",
      ">401, d1=0.697, d2=0.712 g=0.718, a1=54, a2=45\n",
      ">402, d1=0.696, d2=0.712 g=0.719, a1=51, a2=37\n",
      ">403, d1=0.701, d2=0.696 g=0.721, a1=45, a2=45\n",
      ">404, d1=0.700, d2=0.702 g=0.728, a1=43, a2=43\n",
      ">405, d1=0.704, d2=0.697 g=0.725, a1=48, a2=46\n",
      ">406, d1=0.710, d2=0.691 g=0.719, a1=43, a2=53\n",
      ">407, d1=0.698, d2=0.711 g=0.721, a1=40, a2=42\n",
      ">408, d1=0.717, d2=0.699 g=0.720, a1=45, a2=45\n",
      ">409, d1=0.711, d2=0.724 g=0.725, a1=43, a2=26\n",
      ">410, d1=0.705, d2=0.695 g=0.726, a1=42, a2=57\n",
      ">411, d1=0.715, d2=0.691 g=0.728, a1=39, a2=56\n",
      ">412, d1=0.694, d2=0.699 g=0.723, a1=54, a2=46\n",
      ">413, d1=0.704, d2=0.701 g=0.729, a1=46, a2=48\n",
      ">414, d1=0.720, d2=0.701 g=0.730, a1=34, a2=48\n",
      ">415, d1=0.694, d2=0.701 g=0.729, a1=56, a2=40\n",
      ">416, d1=0.701, d2=0.705 g=0.737, a1=45, a2=42\n",
      ">417, d1=0.708, d2=0.687 g=0.726, a1=46, a2=56\n",
      ">418, d1=0.702, d2=0.694 g=0.741, a1=53, a2=51\n",
      ">419, d1=0.721, d2=0.699 g=0.734, a1=35, a2=43\n",
      ">420, d1=0.719, d2=0.692 g=0.733, a1=26, a2=48\n",
      ">421, d1=0.720, d2=0.703 g=0.726, a1=39, a2=40\n",
      ">422, d1=0.699, d2=0.690 g=0.724, a1=50, a2=53\n",
      ">423, d1=0.702, d2=0.685 g=0.725, a1=50, a2=56\n",
      ">424, d1=0.710, d2=0.691 g=0.727, a1=46, a2=51\n",
      ">425, d1=0.713, d2=0.699 g=0.739, a1=37, a2=40\n",
      ">426, d1=0.700, d2=0.686 g=0.736, a1=46, a2=57\n",
      ">427, d1=0.705, d2=0.689 g=0.743, a1=39, a2=50\n",
      ">428, d1=0.709, d2=0.688 g=0.741, a1=45, a2=56\n",
      ">429, d1=0.727, d2=0.684 g=0.739, a1=34, a2=54\n",
      ">430, d1=0.697, d2=0.681 g=0.735, a1=53, a2=60\n",
      ">431, d1=0.705, d2=0.687 g=0.732, a1=48, a2=50\n",
      ">432, d1=0.713, d2=0.686 g=0.734, a1=32, a2=59\n",
      ">433, d1=0.722, d2=0.680 g=0.730, a1=40, a2=65\n",
      ">434, d1=0.704, d2=0.686 g=0.724, a1=39, a2=56\n",
      ">435, d1=0.713, d2=0.691 g=0.731, a1=39, a2=56\n",
      ">436, d1=0.705, d2=0.695 g=0.730, a1=40, a2=43\n",
      ">437, d1=0.709, d2=0.691 g=0.725, a1=37, a2=53\n",
      ">438, d1=0.699, d2=0.685 g=0.740, a1=54, a2=56\n",
      ">439, d1=0.708, d2=0.695 g=0.746, a1=48, a2=51\n",
      ">440, d1=0.713, d2=0.690 g=0.740, a1=34, a2=53\n",
      ">441, d1=0.690, d2=0.687 g=0.742, a1=59, a2=60\n",
      ">442, d1=0.722, d2=0.678 g=0.736, a1=34, a2=65\n",
      ">443, d1=0.694, d2=0.694 g=0.738, a1=51, a2=57\n",
      ">444, d1=0.700, d2=0.684 g=0.740, a1=42, a2=56\n",
      ">445, d1=0.715, d2=0.701 g=0.730, a1=32, a2=42\n",
      ">446, d1=0.707, d2=0.677 g=0.732, a1=37, a2=57\n",
      ">447, d1=0.705, d2=0.694 g=0.734, a1=45, a2=45\n",
      ">448, d1=0.717, d2=0.693 g=0.741, a1=26, a2=57\n",
      ">449, d1=0.720, d2=0.679 g=0.738, a1=28, a2=60\n",
      ">450, d1=0.720, d2=0.687 g=0.737, a1=34, a2=57\n"
     ]
    }
   ],
   "source": [
    "# example of training a stable gan for generating a handwritten digit\n",
    "from os import makedirs\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.initializers import RandomNormal\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(28,28,1)):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# downsample to 14x14\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, input_shape=in_shape))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# downsample to 7x7\n",
    "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# classifier\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# define the standalone generator model\n",
    "def define_generator(latent_dim):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\t# foundation for 7x7 image\n",
    "\tn_nodes = 128 * 7 * 7\n",
    "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(Reshape((7, 7, 128)))\n",
    "\t# upsample to 14x14\n",
    "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# upsample to 28x28\n",
    "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\t# output 28x28x1\n",
    "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
    "\treturn model\n",
    "\n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\tdiscriminator.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(generator)\n",
    "\t# add the discriminator\n",
    "\tmodel.add(discriminator)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\treturn model\n",
    "\n",
    "# load mnist images\n",
    "def load_real_samples():\n",
    "\t# load dataset\n",
    "\t(trainX, trainy), (_, _) = load_data()\n",
    "\t# expand to 3d, e.g. add channels\n",
    "\tX = expand_dims(trainX, axis=-1)\n",
    "\t# select all of the examples for a given class\n",
    "\tselected_ix = trainy == 8\n",
    "\tX = X[selected_ix]\n",
    "\t# convert from ints to floats\n",
    "\tX = X.astype('float32')\n",
    "\t# scale from [0,255] to [-1,1]\n",
    "\tX = (X - 127.5) / 127.5\n",
    "\treturn X\n",
    "\n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "\t# choose random instances\n",
    "\tix = randint(0, dataset.shape[0], n_samples)\n",
    "\t# select images\n",
    "\tX = dataset[ix]\n",
    "\t# generate class labels\n",
    "\ty = ones((n_samples, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = randn(latent_dim * n_samples)\n",
    "\t# reshape into a batch of inputs for the network\n",
    "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
    "\treturn x_input\n",
    "\n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n_samples, 1))\n",
    "\treturn X, y\n",
    "\n",
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
    "\t# prepare fake examples\n",
    "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "\t# scale from [-1,1] to [0,1]\n",
    "\tX = (X + 1) / 2.0\n",
    "\t# plot images\n",
    "\tfor i in range(10 * 10):\n",
    "\t\t# define subplot\n",
    "\t\tpyplot.subplot(10, 10, 1 + i)\n",
    "\t\t# turn off axis\n",
    "\t\tpyplot.axis('off')\n",
    "\t\t# plot raw pixel data\n",
    "\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "\t# save plot to file\n",
    "\tpyplot.savefig('results_baseline/generated_plot_%03d.png' % (step+1))\n",
    "\tpyplot.close()\n",
    "\t# save the generator model\n",
    "\tg_model.save('results_baseline/model_%03d.h5' % (step+1))\n",
    "\n",
    "# create a line plot of loss for the gan and save to file\n",
    "def plot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist):\n",
    "\t# plot loss\n",
    "\tpyplot.subplot(2, 1, 1)\n",
    "\tpyplot.plot(d1_hist, label='d-real')\n",
    "\tpyplot.plot(d2_hist, label='d-fake')\n",
    "\tpyplot.plot(g_hist, label='gen')\n",
    "\tpyplot.legend()\n",
    "\t# plot discriminator accuracy\n",
    "\tpyplot.subplot(2, 1, 2)\n",
    "\tpyplot.plot(a1_hist, label='acc-real')\n",
    "\tpyplot.plot(a2_hist, label='acc-fake')\n",
    "\tpyplot.legend()\n",
    "\t# save plot to file\n",
    "\tpyplot.savefig('results_baseline/plot_line_plot_loss.png')\n",
    "\tpyplot.close()\n",
    "\n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=128):\n",
    "\t# calculate the number of batches per epoch\n",
    "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "\t# calculate the total iterations based on batch and epoch\n",
    "\tn_steps = bat_per_epo * n_epochs\n",
    "\t# calculate the number of samples in half a batch\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# prepare lists for storing stats each iteration\n",
    "\td1_hist, d2_hist, g_hist, a1_hist, a2_hist = list(), list(), list(), list(), list()\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_steps):\n",
    "\t\t# get randomly selected 'real' samples\n",
    "\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "\t\t# update discriminator model weights\n",
    "\t\td_loss1, d_acc1 = d_model.train_on_batch(X_real, y_real)\n",
    "\t\t# generate 'fake' examples\n",
    "\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "\t\t# update discriminator model weights\n",
    "\t\td_loss2, d_acc2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "\t\t# prepare points in latent space as input for the generator\n",
    "\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
    "\t\t# create inverted labels for the fake samples\n",
    "\t\ty_gan = ones((n_batch, 1))\n",
    "\t\t# update the generator via the discriminator's error\n",
    "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "\t\t# summarize loss on this batch\n",
    "\t\tprint('>%d, d1=%.3f, d2=%.3f g=%.3f, a1=%d, a2=%d' %\n",
    "\t\t\t(i+1, d_loss1, d_loss2, g_loss, int(100*d_acc1), int(100*d_acc2)))\n",
    "\t\t# record history\n",
    "\t\td1_hist.append(d_loss1)\n",
    "\t\td2_hist.append(d_loss2)\n",
    "\t\tg_hist.append(g_loss)\n",
    "\t\ta1_hist.append(d_acc1)\n",
    "\t\ta2_hist.append(d_acc2)\n",
    "\t\t# evaluate the model performance every 'epoch'\n",
    "\t\tif (i+1) % bat_per_epo == 0:\n",
    "\t\t\tsummarize_performance(i, g_model, latent_dim)\n",
    "\tplot_history(d1_hist, d2_hist, g_hist, a1_hist, a2_hist)\n",
    "\n",
    "# make folder for results\n",
    "makedirs('results_baseline', exist_ok=True)\n",
    "# size of the latent space\n",
    "latent_dim = 50\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# load image data\n",
    "dataset = load_real_samples()\n",
    "print(dataset.shape)\n",
    "# train model\n",
    "train(generator, discriminator, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
